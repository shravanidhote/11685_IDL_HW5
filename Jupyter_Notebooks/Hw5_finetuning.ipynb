{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:16:14.014268Z",
          "iopub.status.busy": "2023-12-08T22:16:14.013945Z",
          "iopub.status.idle": "2023-12-08T22:16:29.078808Z",
          "shell.execute_reply": "2023-12-08T22:16:29.077932Z",
          "shell.execute_reply.started": "2023-12-08T22:16:14.014242Z"
        },
        "id": "2iJnHVt59YoQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install datasets tiktoken wandb --quiet\n",
        "import tiktoken\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PEyjUk_29itC"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QwMH4qjw08kV"
      },
      "outputs": [],
      "source": [
        "encoder_1 = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5rbZWu3FYvw",
        "outputId": "944a95ab-60a2-482a-f375-ae7835d41f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-08T22:16:33.384043Z",
          "iopub.status.busy": "2023-12-08T22:16:33.383728Z",
          "iopub.status.idle": "2023-12-08T22:16:39.909757Z",
          "shell.execute_reply": "2023-12-08T22:16:39.908656Z",
          "shell.execute_reply.started": "2023-12-08T22:16:33.384013Z"
        },
        "id": "02SVV7jOBga-",
        "outputId": "e08f08b7-0a83-416c-afa7-6619b80a9370",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73248 sha256=10c115fad4dff013b01a8825bfaf144b22d1877e1313acf6454f4308ba851ba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/76/ca/e58f8afa83166a0e68f0d5cd2e7f99d260bdc40e35da080eee\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.16\n",
            "    Uninstalling kaggle-1.5.16:\n",
            "      Successfully uninstalled kaggle-1.5.16\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"shravanidhote12\",\"key\":\"d238c4c92c6c26cc53fcc6382afeb017\"}') # Put your kaggle username & key here\n",
        "\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:16:54.230480Z",
          "iopub.status.busy": "2023-12-08T22:16:54.230113Z",
          "iopub.status.idle": "2023-12-08T22:17:04.489569Z",
          "shell.execute_reply": "2023-12-08T22:17:04.488691Z",
          "shell.execute_reply.started": "2023-12-08T22:16:54.230444Z"
        },
        "id": "MSJ7ZMf4Bj0F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "main_data = np.load('/content/drive/MyDrive/IDL_HW5/complete_data_2.npz')\n",
        "\n",
        "train_dataset = main_data['train']\n",
        "validation_dataset   = main_data['val']\n",
        "test_dataset  = main_data['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZxCIhD-BskY"
      },
      "source": [
        "# Finetuning loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:04.492859Z",
          "iopub.status.busy": "2023-12-08T22:17:04.492565Z",
          "iopub.status.idle": "2023-12-08T22:17:07.532250Z",
          "shell.execute_reply": "2023-12-08T22:17:07.531292Z",
          "shell.execute_reply.started": "2023-12-08T22:17:04.492833Z"
        },
        "id": "JiH4Kv7LBrD6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Fine_tuning_dataloader(torch.utils.data.DataLoader):\n",
        "    def __init__(self, data, bs=32):\n",
        "\n",
        "        self.data, self.bs, len_data = data, bs, len(data)\n",
        "\n",
        "        temp = len_data / self.bs\n",
        "        self.batch_count = math.ceil(temp)\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return self.batch_count\n",
        "\n",
        "    def __iter__(self):\n",
        "\n",
        "        np.random.shuffle(self.data)\n",
        "\n",
        "        for point in range(0, len(self.data), self.bs):\n",
        "\n",
        "            temp = point + self.bs\n",
        "\n",
        "            ip = self.data[point:temp, :]\n",
        "\n",
        "            column_except_first = ip[:, 1:]\n",
        "\n",
        "            column_of_eot_tokens = np.full((ip.shape[0], 1), encoder_1.eot_token)\n",
        "\n",
        "            op = np.concatenate((column_except_first, column_of_eot_tokens), axis=1)\n",
        "\n",
        "            ip_as_int64 = ip.astype(np.int64)\n",
        "            op_as_int64 = op.astype(np.int64)\n",
        "\n",
        "            yield torch.from_numpy(ip_as_int64), torch.from_numpy(op_as_int64)\n",
        "\n",
        "\n",
        "train_dataset_fineloader = Fine_tuning_dataloader(train_dataset)\n",
        "val_dataset_fineloader = Fine_tuning_dataloader(validation_dataset)\n",
        "test_dataset_fineloader = Fine_tuning_dataloader(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN829-5FHF2s"
      },
      "source": [
        "## Model Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:07.655129Z",
          "iopub.status.busy": "2023-12-08T22:17:07.654447Z",
          "iopub.status.idle": "2023-12-08T22:17:07.665557Z",
          "shell.execute_reply": "2023-12-08T22:17:07.664733Z",
          "shell.execute_reply.started": "2023-12-08T22:17:07.655105Z"
        },
        "id": "zdcTPzonB17X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Architecture Configuration\n",
        "\n",
        "n_head = 6\n",
        "num_heads = 6\n",
        "n_embd = 512\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "block_size = 256\n",
        "batch_size = 40\n",
        "learning_rate = 3e-4\n",
        "\n",
        "vocab_size = encoder_1.n_vocab\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        # Linear layers for key, query, and value\n",
        "        self.linear_layers = nn.ModuleList([\n",
        "            nn.Linear(n_embd, head_size, bias=False) for _ in range(3)\n",
        "        ])\n",
        "        self.key_layer, self.query_layer, self.value_layer = self.linear_layers\n",
        "        # Lower triangular mask for attention\n",
        "        identity_matrix = torch.eye(block_size)\n",
        "        lower_triangular_mask = torch.tril(identity_matrix)\n",
        "        self.register_buffer('tril', lower_triangular_mask)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Self-attention mechanism\n",
        "        batch_size = x.shape[0]\n",
        "        time_steps = x.shape[1]\n",
        "        channels = x.shape[2]\n",
        "        key, query = self.key_layer(x), self.query_layer(x)\n",
        "        key_transposed = key.transpose(-2, -1)\n",
        "        attention_scores = torch.matmul(query, key_transposed) / torch.sqrt(torch.tensor(key.shape[-1], dtype=torch.float32))\n",
        "        attention_mask = torch.where(self.tril[:time_steps, :time_steps] == 0, float('-inf'), attention_scores)\n",
        "        attention_probs = self.drop(torch.nn.functional.log_softmax(attention_mask, dim=-1).exp())\n",
        "        value = self.value_layer(x)\n",
        "        output = attention_probs @ value\n",
        "        return output\n",
        "\n",
        "# Define Multi-Head Attention module\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" Multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList()\n",
        "        for _ in range(num_heads):\n",
        "            self.heads.append(Head(head_size))\n",
        "        self.projection = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Combine multiple self-attention heads\n",
        "        individual_heads = [head_module(x) for head_module in self.heads]\n",
        "        concatenated_heads_expanded = torch.cat(individual_heads, dim=-1)\n",
        "        projected_out = self.projection(concatenated_heads_expanded)\n",
        "        dropped_out = self.drop(projected_out)\n",
        "        return dropped_out\n",
        "\n",
        "# Define FeedForward module\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd, dropout):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_embd, 4 * n_embd)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(4 * n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # FeedForward neural network\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "# Define a Block in the GPT model\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        self.self_attention = MultiHeadAttention(n_head, (n_embd // n_head))\n",
        "        self.feed_forward = FeedForward(n_embd, dropout)\n",
        "        self.linearlayer1, self.linearlayer2 = nn.LayerNorm(n_embd), nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block in the GPT model\n",
        "        x = x + self.self_attention(self.linearlayer1(x)) + self.feed_forward(self.linearlayer2(x))\n",
        "        return x\n",
        "\n",
        "# Define the GPT Language Model\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_emb_tbl = nn.Embedding(vocab_size, n_embd)\n",
        "        self.pos_emb_tbl = nn.Embedding(block_size, n_embd)\n",
        "        attention_blocks = [Block(n_embd, n_head=n_head) for _ in range(n_layer)]\n",
        "        self.attention_blocks = nn.Sequential(*attention_blocks)\n",
        "        self.layer_norm_final = nn.LayerNorm(n_embd)\n",
        "        self.mode_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        # Initialize weights for linear and embedding layers\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            torch.nn.init.zeros_(module.bias) if hasattr(module, 'bias') and module.bias is not None else None\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Forward pass through the GPT model\n",
        "        embedding_indices = idx\n",
        "        token_embeddings = self.token_emb_tbl(embedding_indices)\n",
        "        pos_indices = torch.arange(idx.shape[1], device=device)\n",
        "        positional_embeddings = self.pos_emb_tbl(pos_indices).unsqueeze(0)\n",
        "        normalized_embeddings = self.layer_norm_final(self.attention_blocks(token_embeddings + positional_embeddings.expand_as(token_embeddings)))\n",
        "        logits = self.mode_head(normalized_embeddings)\n",
        "        loss = F.cross_entropy(logits.flatten(0, 1), targets.flatten()) if targets is not None else None\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # Generate new tokens\n",
        "        for _ in range(max_new_tokens):\n",
        "            currentlogits, _ = self.forward(idx[:, -block_size:])\n",
        "            currentlogits = currentlogits[:, -1, :]\n",
        "            nexttoken = torch.multinomial(F.softmax(currentlogits, dim=-1), num_samples=1).view(-1, 1)\n",
        "            idx = torch.hstack((idx, nexttoken))\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:07.808842Z",
          "iopub.status.busy": "2023-12-08T22:17:07.808510Z",
          "iopub.status.idle": "2023-12-08T22:17:07.821101Z",
          "shell.execute_reply": "2023-12-08T22:17:07.820005Z",
          "shell.execute_reply.started": "2023-12-08T22:17:07.808816Z"
        },
        "id": "HE_EujBUB6uU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_tokens_greedily(initial_indices, newtokens):\n",
        "  for i in range(newtokens):\n",
        "        indices_cond = initial_indices[:, -block_size:]\n",
        "        with torch.no_grad():\n",
        "          output_logits, loss = model(indices_cond)\n",
        "        output_logits = output_logits[:, -1, :]\n",
        "        prob = torch.nn.functional.softmax(output_logits, dim=-1)\n",
        "        max_indices = torch.max(prob, dim=-1, keepdim=True)[1]\n",
        "        initial_indices = torch.cat((initial_indices, max_indices), dim=1)\n",
        "  return initial_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byHSOu57CH04"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:12.099060Z",
          "iopub.status.busy": "2023-12-08T22:17:12.098749Z",
          "iopub.status.idle": "2023-12-08T22:17:13.481242Z",
          "shell.execute_reply": "2023-12-08T22:17:13.480247Z",
          "shell.execute_reply.started": "2023-12-08T22:17:12.099034Z"
        },
        "id": "g5J0quFAC3xr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# wandb.finish()\n",
        "import wandb\n",
        "wandb.login(key=\"bc23ae38b83159616a86ecc84dc25bc2e82d4da4\")\n",
        "\n",
        "run = wandb.init(\n",
        "    name = \"hw5_finetuning-Kaggle-2\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True,  ### Allows reinitalizing runs when you re-run this cell\n",
        "    # id = \"ii86awr7\",  # Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\",  ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw5-ablations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVdNVx-sB74O"
      },
      "source": [
        "# Initialize model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:07.823239Z",
          "iopub.status.busy": "2023-12-08T22:17:07.822298Z",
          "iopub.status.idle": "2023-12-08T22:17:12.092083Z",
          "shell.execute_reply": "2023-12-08T22:17:12.091128Z",
          "shell.execute_reply.started": "2023-12-08T22:17:07.823195Z"
        },
        "id": "P-kXEg7bB83a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = GPTLanguageModel()\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor =0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:12.093486Z",
          "iopub.status.busy": "2023-12-08T22:17:12.093191Z",
          "iopub.status.idle": "2023-12-08T22:17:12.097594Z",
          "shell.execute_reply": "2023-12-08T22:17:12.096651Z",
          "shell.execute_reply.started": "2023-12-08T22:17:12.093461Z"
        },
        "id": "vC2kiVUUB_Ke",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# path = \"/content/drive/MyDrive/IDL/HW5/Finetune_tiral/xyz.pth\"\n",
        "# or\n",
        "# url = wandb.restore(\"xyz.pth\").name\n",
        "# model.load_state_dict(torch.load(path,map_location=torch.device(device))[\"model_state_dict\"])\n",
        "# optimizer.load_state_dict(torch.load(path)[\"optimizer_state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:31.546150Z",
          "iopub.status.busy": "2023-12-08T22:17:31.545863Z",
          "iopub.status.idle": "2023-12-08T22:17:31.553242Z",
          "shell.execute_reply": "2023-12-08T22:17:31.552314Z",
          "shell.execute_reply.started": "2023-12-08T22:17:31.546123Z"
        },
        "id": "tvhNFazACBtj",
        "outputId": "fdee9466-8c48-4023-fa89-ee97221499c7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate:  0.0001\n",
            "Set Learning rate to:  0.0001\n"
          ]
        }
      ],
      "source": [
        "avg = 0\n",
        "sum = 0\n",
        "for param_group in optimizer.param_groups:\n",
        "    avg = avg + param_group['lr']\n",
        "    sum = sum+ 1\n",
        "\n",
        "lr = avg/sum\n",
        "print(\"Learning rate: \",lr)\n",
        "\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = 1e-04\n",
        "\n",
        "avg = 0\n",
        "sum = 0\n",
        "for param_group in optimizer.param_groups:\n",
        "    avg = avg + param_group['lr']\n",
        "    sum = sum+ 1\n",
        "lr = avg/sum\n",
        "print(\"Set Learning rate to: \",lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:32.687662Z",
          "iopub.status.busy": "2023-12-08T22:17:32.686730Z",
          "iopub.status.idle": "2023-12-08T22:17:32.696703Z",
          "shell.execute_reply": "2023-12-08T22:17:32.695924Z",
          "shell.execute_reply.started": "2023-12-08T22:17:32.687610Z"
        },
        "id": "pOkviV29CFRe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def generate_and_display_sample(max_tokens=20):\n",
        "\n",
        "    input_content = [\"This chocolate cake \", \"The government is doing\"]\n",
        "\n",
        "    encoded_content = encoder_1.encode_batch(input_content)\n",
        "    content_tensors = torch.tensor(encoded_content)\n",
        "    content_tensors = content_tensors.to(device)\n",
        "\n",
        "    contents_decoded = encoder_1.decode_batch(model.generate(content_tensors, max_tokens).cpu().numpy())\n",
        "\n",
        "    print(\"\\n####\\n\".join(contents_decoded))\n",
        "\n",
        "\n",
        "interval_to_save = 1500\n",
        "\n",
        "dir_to_save= \"/content/drive/MyDrive/IDL_HW5/HW5/finetuning_trials/checkpoints\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:32.712574Z",
          "iopub.status.busy": "2023-12-08T22:17:32.711523Z",
          "iopub.status.idle": "2023-12-08T22:17:32.726922Z",
          "shell.execute_reply": "2023-12-08T22:17:32.725695Z",
          "shell.execute_reply.started": "2023-12-08T22:17:32.712535Z"
        },
        "id": "Lqfj012wCKfi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def validate(loader, epoch, train_iter, loss):\n",
        "\n",
        "    progress_bar = tqdm(total=len(loader), dynamic_ncols=True,\n",
        "                   leave=False, pos=0, desc='Validate', ncols=5)\n",
        "\n",
        "    training_error = 0.0\n",
        "\n",
        "    for i, (p, q) in enumerate(loader):\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        p, q = p.to(device), q.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "              model_out = model(p, q)\n",
        "              logits = model_out[0]\n",
        "              loss = model_out[1]\n",
        "\n",
        "        training_error = training_error + loss\n",
        "\n",
        "        progress_bar.set_postfix(loss=f\"{training_error / (train_iter + 1):.04f}\").update()\n",
        "\n",
        "        del p, q, logits\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    return training_error / i\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6kbiqhazNjb"
      },
      "source": [
        "### Run 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BLBLky-v9RZW"
      },
      "outputs": [],
      "source": [
        "evaluation_interval = 10000\n",
        "max_iterations = 500000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-08T22:17:32.764879Z",
          "iopub.status.busy": "2023-12-08T22:17:32.764603Z"
        },
        "id": "1IGHRnvrNAoF",
        "outputId": "95c8bde0-f5ed-47ca-e5cb-84b49a86ebca",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "\n",
            "\n",
            " ######################################## \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 1/51675 [00:06<90:34:56,  6.31s/it, loss=4.8965]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 1  Train loss: 4.896520614624023  Elapsed Time: 0m 6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   4%|▍         | 2001/51675 [31:23<13:02:03,  1.06it/s, loss=4.8026]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 2001  Train loss: 4.802559852600098  Elapsed Time: 31m 4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   8%|▊         | 4001/51675 [1:02:49<12:29:51,  1.06it/s, loss=4.8019]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 4001  Train loss: 4.801863193511963  Elapsed Time: 62m 39s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  12%|█▏        | 6001/51675 [1:34:09<11:56:56,  1.06it/s, loss=4.7996]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 6001  Train loss: 4.799614429473877  Elapsed Time: 94m 9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  15%|█▌        | 8001/51675 [2:05:27<11:23:50,  1.06it/s, loss=4.7972]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 8001  Train loss: 4.797238826751709  Elapsed Time: 125m 8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  19%|█▉        | 10000/51675 [2:36:44<10:57:30,  1.06it/s, loss=4.7962]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 10000: train loss 4.795764923095703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss:  tensor(4.8324, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  19%|█▉        | 10001/51675 [2:52:11<3226:36:41, 278.73s/it, loss=4.7962]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 10001  Train loss: 4.796226978302002  Elapsed Time: 156m 36s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  23%|██▎       | 12001/51675 [3:23:20<10:17:04,  1.07it/s, loss=4.7912]   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 12001  Train loss: 4.791209697723389  Elapsed Time: 203m 20s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  27%|██▋       | 14001/51675 [3:54:25<9:46:42,  1.07it/s, loss=4.7869] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 14001  Train loss: 4.7868757247924805  Elapsed Time: 234m 6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  31%|███       | 16001/51675 [4:25:33<9:15:07,  1.07it/s, loss=4.7827]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 16001  Train loss: 4.782687664031982  Elapsed Time: 265m 24s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  35%|███▍      | 18001/51675 [4:56:38<8:41:46,  1.08it/s, loss=4.7794]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 18001  Train loss: 4.779421806335449  Elapsed Time: 296m 38s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  39%|███▊      | 20000/51675 [5:27:43<8:13:51,  1.07it/s, loss=4.7767]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 20000: train loss 4.776421070098877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss:  tensor(4.8193, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  39%|███▊      | 20001/51675 [5:43:34<2516:31:32, 286.02s/it, loss=4.7766]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 20001  Train loss: 4.776648044586182  Elapsed Time: 327m 25s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  43%|████▎     | 22001/51675 [6:14:38<7:38:44,  1.08it/s, loss=4.7737]    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 22001  Train loss: 4.7736616134643555  Elapsed Time: 374m 29s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  46%|████▋     | 24001/51675 [6:45:41<7:15:03,  1.06it/s, loss=4.7715]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 24001  Train loss: 4.771488666534424  Elapsed Time: 405m 41s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  50%|█████     | 26001/51675 [7:16:46<6:39:04,  1.07it/s, loss=4.7693]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 26001  Train loss: 4.7693190574646  Elapsed Time: 436m 27s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  54%|█████▍    | 28001/51675 [7:47:51<6:09:31,  1.07it/s, loss=4.7677]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 28001  Train loss: 4.76768159866333  Elapsed Time: 467m 42s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  58%|█████▊    | 30000/51675 [8:18:55<5:35:44,  1.08it/s, loss=4.7656]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 30000: train loss 4.765425205230713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss:  tensor(4.8148, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  58%|█████▊    | 30001/51675 [8:34:51<1730:35:06, 287.45s/it, loss=4.7656]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 30001  Train loss: 4.7655792236328125  Elapsed Time: 514m 51s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  62%|██████▏   | 32001/51675 [9:05:53<5:04:39,  1.08it/s, loss=4.7640]    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 32001  Train loss: 4.7639970779418945  Elapsed Time: 545m 35s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  65%|██████▍   | 33365/51675 [9:54:56<1400:13:51, 275.30s/it, loss=4.7630]wandb: Network error (SSLError), entering retry loop.\n",
            "Train:  65%|██████▍   | 33374/51675 [11:54:28<3314:21:07, 651.97s/it, loss=4.7630]"
          ]
        }
      ],
      "source": [
        "\n",
        "# for epoch in range(5):\n",
        "\n",
        "#     epoch_number = epoch + 1\n",
        "#     print(f\"Epoch: {epoch_number}\")\n",
        "\n",
        "#     progress_bar = tqdm(total=len(train_dataset_fineloader), dynamic_ncols=True,\n",
        "#                    leave=False, desc='Train', ncols=5, position=0)\n",
        "\n",
        "#     train_loss, start_time = 0, time.time()\n",
        "\n",
        "#     for step, (p, q) in enumerate(train_dataset_fineloader):\n",
        "\n",
        "#         if (step != 0 and step % evaluation_interval == 0) or step == max_iterations - 1:\n",
        "\n",
        "#             filename = f\"finetuning_2_{epoch}_{step}_{loss:.4f}.pth\"\n",
        "#             checkpoint_path = os.path.join(dir_to_save, filename)\n",
        "\n",
        "#             model_state = model.state_dict()\n",
        "#             optimizer_state = optimizer.state_dict()\n",
        "\n",
        "#             states_dict = {'model_state_dict': model_state, 'optimizer_state_dict': optimizer_state}\n",
        "#             torch.save(states_dict, checkpoint_path)\n",
        "\n",
        "#             wandb.save(checkpoint_path)\n",
        "\n",
        "#             average_train_loss = float(train_loss / (step + 1))\n",
        "#             print(f\"Step {step}: Average train loss {average_train_loss}\")\n",
        "\n",
        "#             validation_loss = validate(val_dataset_fineloader, epoch, step, average_train_loss)\n",
        "#             print(\"Validation loss: \", validation_loss)\n",
        "\n",
        "#             wandb.log({ 'train_loss': average_train_loss, 'valid_loss': validation_loss })\n",
        "\n",
        "\n",
        "#         p, q = p.to(device), q.to(device)\n",
        "\n",
        "\n",
        "#         result, error = model(p, q)\n",
        "\n",
        "#         train_loss = train_loss + error\n",
        "\n",
        "#         optimizer.zero_grad(set_to_none=True); error.backward(); optimizer.step()\n",
        "\n",
        "#         average_loss = train_loss / (step + 1)\n",
        "#         formatted_loss = \"{:.04f}\".format(average_loss)\n",
        "#         progress_bar.set_postfix(loss=formatted_loss)\n",
        "\n",
        "\n",
        "#         if step % 30 == 0:\n",
        "\n",
        "#             # average_train_loss = train_loss / (step + 1)\n",
        "#             # wandb.log({'train_loss': float(average_train_loss)})\n",
        "\n",
        "#             mins = int((time.time() - start_time) // 60)\n",
        "#             secs = int((time.time() - start_time) % 60)\n",
        "\n",
        "#         if step % 2000 == 0:\n",
        "\n",
        "#             iteration = step + 1\n",
        "#             average_train_loss = train_loss / iteration\n",
        "#             elapsed_time_formatted = f\"{mins}m {secs}s\"\n",
        "#             print(\"Iter: {}  Train loss: {:.4f}  Elapsed Time: {}\".format(iteration, float(average_train_loss), elapsed_time_formatted))\n",
        "\n",
        "#         progress_bar.update()\n",
        "\n",
        "#         del p, q, result\n",
        "\n",
        "#         gc.collect()\n",
        "\n",
        "#         torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwsTznZg1IBd"
      },
      "source": [
        "### Run 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LpM3_WvEwjX",
        "outputId": "4ecce0f0-052c-4099-dd5b-10cfd5274f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  1\n",
            "\n",
            "\n",
            " ######################################## \n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   0%|          | 1/51675 [00:05<79:52:45,  5.56s/it, loss=3.7210]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 1  Train loss: 3.7209949493408203  Elapsed Time: 0m 5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   4%|▍         | 2001/51675 [11:11<4:36:23,  3.00it/s, loss=3.1947]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 2001  Train loss: 3.1946802139282227  Elapsed Time: 11m 5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:   8%|▊         | 4001/51675 [22:16<4:26:41,  2.98it/s, loss=3.1872]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 4001  Train loss: 3.1871705055236816  Elapsed Time: 22m 13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  12%|█▏        | 6001/51675 [33:20<4:13:24,  3.00it/s, loss=3.1806]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 6001  Train loss: 3.1806278228759766  Elapsed Time: 33m 20s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  15%|█▌        | 8001/51675 [44:26<4:02:57,  3.00it/s, loss=3.1786]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 8001  Train loss: 3.178565263748169  Elapsed Time: 44m 19s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  19%|█▉        | 10000/51675 [55:33<3:50:18,  3.02it/s, loss=3.1762]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 10000: train loss 3.175849199295044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val loss:  tensor(3.2184, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  19%|█▉        | 10001/51675 [1:04:23<1840:47:43, 159.02s/it, loss=3.1762]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 10001  Train loss: 3.1761674880981445  Elapsed Time: 55m 30s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  23%|██▎       | 12001/51675 [1:15:52<3:46:10,  2.92it/s, loss=3.1420]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 12001  Train loss: 3.1419801712036133  Elapsed Time: 75m 52s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  27%|██▋       | 14001/51675 [1:27:16<3:32:22,  2.96it/s, loss=3.1161]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 14001  Train loss: 3.116067886352539  Elapsed Time: 87m 9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  31%|███       | 16001/51675 [1:38:37<3:23:48,  2.92it/s, loss=3.0960]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 16001  Train loss: 3.0960099697113037  Elapsed Time: 98m 33s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  35%|███▍      | 18001/51675 [1:50:00<3:10:03,  2.95it/s, loss=3.0798]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter: 18001  Train loss: 3.079780101776123  Elapsed Time: 110m 0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  38%|███▊      | 19724/51675 [1:59:49<3:03:34,  2.90it/s, loss=3.0686]"
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(5):\n",
        "\n",
        "    epoch_number = epoch + 1\n",
        "    print(f\"Epoch: {epoch_number}\")\n",
        "\n",
        "    progress_bar = tqdm(total=len(train_dataset_fineloader), dynamic_ncols=True,\n",
        "                   leave=False, desc='Train', ncols=5, position=0)\n",
        "\n",
        "    train_loss, start_time = 0, time.time()\n",
        "\n",
        "    for step, (p, q) in enumerate(train_dataset_fineloader):\n",
        "\n",
        "        if (step != 0 and step % evaluation_interval == 0) or step == max_iterations - 1:\n",
        "\n",
        "            filename = f\"finetuning_2_{epoch}_{step}_{loss:.4f}.pth\"\n",
        "            checkpoint_path = os.path.join(dir_to_save, filename)\n",
        "\n",
        "            model_state = model.state_dict()\n",
        "            optimizer_state = optimizer.state_dict()\n",
        "\n",
        "            states_dict = {'model_state_dict': model_state, 'optimizer_state_dict': optimizer_state}\n",
        "            torch.save(states_dict, checkpoint_path)\n",
        "\n",
        "            wandb.save(checkpoint_path)\n",
        "\n",
        "            average_train_loss = float(train_loss / (step + 1))\n",
        "            print(f\"Step {step}: Average train loss {average_train_loss}\")\n",
        "\n",
        "            validation_loss = validate(val_dataset_fineloader, epoch, step, average_train_loss)\n",
        "            print(\"Validation loss: \", validation_loss)\n",
        "\n",
        "            wandb.log({ 'train_loss': average_train_loss, 'valid_loss': validation_loss })\n",
        "\n",
        "\n",
        "        p, q = p.to(device), q.to(device)\n",
        "\n",
        "\n",
        "        result, error = model(p, q)\n",
        "\n",
        "        train_loss = train_loss + error\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True); error.backward(); optimizer.step()\n",
        "\n",
        "        average_loss = train_loss / (step + 1)\n",
        "        formatted_loss = \"{:.04f}\".format(average_loss)\n",
        "        progress_bar.set_postfix(loss=formatted_loss)\n",
        "\n",
        "\n",
        "        if step % 30 == 0:\n",
        "\n",
        "            average_train_loss = train_loss / (step + 1)\n",
        "            wandb.log({'train_loss': float(average_train_loss)})\n",
        "\n",
        "            mins = int((time.time() - start_time) // 60)\n",
        "            secs = int((time.time() - start_time) % 60)\n",
        "\n",
        "        if step % 2000 == 0:\n",
        "\n",
        "            iteration = step + 1\n",
        "            average_train_loss = train_loss / iteration\n",
        "            elapsed_time_formatted = f\"{mins}m {secs}s\"\n",
        "            print(\"Iter: {}  Train loss: {:.4f}  Elapsed Time: {}\".format(iteration, float(average_train_loss), elapsed_time_formatted))\n",
        "\n",
        "        progress_bar.update()\n",
        "\n",
        "        del p, q, result\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ8vLNjq0VgP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4121180,
          "sourceId": 7140466,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4121202,
          "sourceId": 7140493,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4123939,
          "sourceId": 7144409,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
